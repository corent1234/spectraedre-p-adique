\documentclass[a4paper,12pt]{article}

\newenvironment{proof}{\hbox{}\vspace{-0.8cm} {\bf Proof:}}{\hfill $\Box$}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs} 
\usepackage{graphicx}
\usepackage{color}
\usepackage{ulem}
\usepackage{bm}

\usepackage{cleveref}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{algorithm}{Algorithm}
\newtheorem{conjecture}{Conjecture}
\newtheorem{condition}{Condition}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\newtheorem{problem}{Problem}
\newtheorem{example}{Example}
\newtheorem{notation}{Notation}
\usepackage{booktabs}

\textheight235mm
\textwidth165mm
\voffset-10mm
\hoffset-12.5mm
\parindent0cm
\parskip2mm


\usepackage{stmaryrd} %for double brackets

%\usepackage{mathptmx}

% updates

\newcommand{\R}{\mathbb{R}} % real numbers
\newcommand{\C}{\mathbb{C}} % complex numbers
\newcommand{\N}{\mathbb{N}} % integers
\newcommand{\allmat}{\mathbb{M}} % matrices
\newcommand{\sym}{\mathbb{S}} % matrices symétriques
\newcommand{\PP}{\mathcal{P}}
\newcommand{\Qc}{\mathcal{Q}}
\renewcommand{\span}[1]{{\text{span}(#1)}} % simone's comments
\newcommand{\aff}[1]{{\text{aff}(#1)}} % simone's comments
\newcommand{\relint}[1]{{\text{relint}(#1)}} % simone's comments
\newcommand{\calL}{\mathcal{L}} % simone's comments

\newcommand{\simone}[1]{{\color{blue} #1}} % simone's comments
\newcommand{\corentin}[1]{{\color{red} #1}} % corentin's comments
\newcommand{\tristan}[1]{{\color{red} #1}} % tristan's comments

%p-adic commands
\DeclareMathOperator{\val}{val}
\def\QQ{\ensuremath{\mathbb{Q}}}
\def\ZZ{\ensuremath{\mathbb{Z}}}
\newcommand{\OK}{\mathcal{O}_K}

\newcommand{\GL}{\mathrm{GL}}

\newcommand{\exend}{\hfill $\blacksquare$}


\usepackage{biblatex}
\addbibresource{../rapport/bibstage.bib}

\title{\bf Title}

\begin{document}

\author{Corentin Cornou$^{1}$, Simone Naldi$^{2,3}$ and Tristan Vaccon$^{2}$}

\footnotetext[1]{ENS Paris-Saclay, Université Paris-Saclay, France.}
\footnotetext[2]{Université de Limoges, CNRS, XLIM, UMR 7252, F-87000 Limoges, France.}
\footnotetext[3]{Sorbonne Université, CNRS, LIP6, Equipe PolSys, F-75005 Paris, France.}

\date{Draft of \today}

\maketitle

\begin{abstract}
\end{abstract}

\tableofcontents

\section{Introduction}

\subsection{Context and motivations}

%Il faudra entre autre mentionner (et peut être motiver l'approche p-adique) :
%\begin{itemize}
%\item les questions ouvertes de complexité concernant la programmation semidefinie (pas clair si NP $\cap$ co-NP
%  dans le modele de Turing)
%\item les questions ouvertes géométriques (Conjecture de Lax)
%\end{itemize}


\subsection{Main results}



\section{Preliminaries}

\subsection{Notation}

Throughout the paper, $K$ refers to a complete,
discrete valuation field, $\val : K \twoheadrightarrow \ZZ \cup \{+\infty\}$ to its valuation,
$\OK$ its ring of integers and $\pi$ a uniformizer.
For $k \in \N$, we write $O(\pi^k)$ for $\pi^k \OK$.
A typical example of $K$ as above is the field of $p$-adic numbers 
$\QQ_p$ (equipped with the $p$-adic valuation). For this example, we 
have $\OK = \ZZ_p$.
Another example is the field of Laurent series
$K=\QQ(\!(t)\!)$ equiped with $t$-adic valuation,
in which case $\OK = \QQ \llbracket t \rrbracket$.
We refer to \cite{Serre:1979} for a
general introduction to such fields
and to Caruso's course on $p$-adic computations \cite{caruso_computations_2017}
for an introduction to effective computations over $p$-adic numbers.

The $K$-vector space of polynomials of degree $\leq d$ on $x=(x_1,\ldots,x_n)$
with coefficients in $K$ is denoted by $K[x]_{d}$. The vector space of matrices of
size $p \times q$ with entries in $K$ is denoted by $\allmat_{p,q}(K)$. For the sake
of ease of writing, block-diagonal matrices with blocks $B_1,\ldots,B_d$ are denoted by
$B_1 \oplus \cdots \oplus B_d$.

\subsection{Real spectrahedra}

Let $\sym_d(\R) \subset \allmat_{d,d}(\R)$ be the vector space of $d \times d$ real symmetric
matrices. A matrix $M \in \sym_d(\R)$
is called \emph{positive semidefinite} ($M \succeq 0$) whenever the quadratic
form $x \mapsto x^TMx$ is nonnegative for all $x\in \R^n$. By the Spectral Theorem, $M \succeq 0$
if and only if the eigenvalues of $M$ are nonnegative, and this is equivalent to all the principal minors
of $M$ being nonnegative. The set of positive semidefinite matrices, denoted $\sym_d^+(\R) \subset \sym_d(\R)$,
is a closed convex cone with non-empty interior in $\sym_d(\R)$.

Let $A_0,A_1,\ldots,A_n \in \sym_d(\R)$, and let $\calL = A_0+\span{A_1,\ldots,A_n}$ be the affine space
containing $A_0$ and with direction the vector space spanned by $A_1,\ldots,A_n$ (which we assume linearly
independent). The intersection $\calL \cap \sym_d^+(\R) = \left\{A(x) := A_0+\sum_i x_i A_i \in \sym_d(\R) :
A(x) \succeq 0\right\}$, or
equivalently, its pre-image $S = \{x \in \R^n : A(x) \succeq 0\}$ under the map $x \mapsto A(x)$, is called
a \emph{real spectrahedron}. As (linear preimage of) affine sections of $\sym_d^+(\R)$, real spectrahedra
are closed convex sets, but might have empty interior in $\calL$ (resp. in $\R^n$).
Moreover, they are basic semialgebraic sets, indeed they are defined by sign conditions on the principal
minors of the defining matrix as well as sign conditions on the coefficients of its characteristic polynomial
(cf. \Cref{ell3}).

\begin{example}\label{ell3}
  Let $d=n=3$. The $3$-elliptope is the three-dimensional spectrahedron given by
  $$
  \mathcal{E}_3 :=
  \left\{
  x
  \in \R^3 :
  \begin{bmatrix}
    1 & x_1 & x_2 \\
    x_1 & 1 & x_3 \\
    x_2 & x_3 & 1
  \end{bmatrix}
  \succeq 0
  \right\}
  =
  \left\{
  x
  \in \R^3 :
  \begin{array}{r}
    3-x_1^2-x_2^2-x_3^2 \geq 0 \\
    1+2x_1x_2x_3-x_1^2-x_2^2-x_3^2 \geq 0
  \end{array}
  \right\}.
  $$
  The polynomials on the right are the (non-constant) coefficients of the univariate polynomial
  $p(t) = \det(A(x)+t I_3)$,
  whose roots are the opposites of the eigenvalues of the defining matrix. Equivalently $\mathcal{E}_3$
  is defined by positivity of the principal minors of the defining matrix:
  $$
  1-x_1^2 \geq 0, \,\,\, 1-x_2^2 \geq 0, \,\,\, 1-x_3^2 \geq 0 \,\,\, \text{ and } \,\,\, 1+2x_1x_2x_3-x_1^2-x_2^2-x_3^2 \geq 0
  $$
  \exend
\end{example}

The optimization problem of miminizing a linear function over a real spectrahedron is called \emph{semidefinite programming} (SDP). Given $c \in \R^n$ and $A_0,A_1,\ldots,A_n \in \sym_d(\R)$, the corresponding semidefinite program is defined (in standard dual form) as
\begin{equation}
  \label{SDP}
\begin{array}{rcll}
  p^* & := & \inf_{x \in \R^n} & \left\langle c, x \right\rangle \\
  &    & \text{s.t.}         & A_0+\sum_{i=1}^n x_i A_i \succeq 0.
\end{array}
\end{equation}
Real polyhedra (subsets of $\R^n$ defined by finitely many affine inequalities) are special cases of real
spectrahedra, where the defining matrices $A_0, \ldots, A_n$ can be chosen diagonal, so that $A(x) =
\ell_1(x) \oplus \cdots \oplus \ell_d(x)$. In other words, SDP is a generalization of Linear Programming (LP).

In a fixed-precision model of computation, SDP is solvable in polynomial time in the input size (matrix size,
number of variables, bit size of the coefficients), in $\log(\frac{1}{\varepsilon})$ (where $\varepsilon$ is the
precision) and $\log(\frac{1}{R})$, where $R$ is an {\it a priori} upper bound on the norm of a solution,
cf. \cite[Sec.1.9]{deKlerk}. In exact arithmetic, the complexity status of SDP is essentially open but complexity
bounds are known based either on general quantifier elimination \cite{ramana1997exact,porkolab1997complexity}
or by exploiting the determinantal structure of the constraints \cite{henrion2016exact}.

A more general class of convex semialgebraic sets are obtained by linear projections of real spectrahedra
called \emph{semidefinite representable sets} (or spectrahedral shadows): these are sets of the form
$$
P = \left\{x = \left[\begin{smallmatrix} x_1 \\ \vdots \\ x_n \end{smallmatrix}\right] \in \R^n : \exists\,y\in\R^p, \, A_0 + \sum_{i=1}^n x_i A_i + \sum_{j=1}^p y_j B_j \succeq 0\right\}
$$

\begin{example}
\label{fermat_quartic}
The basic closed semialgebraic set $P = \{(x_1,x_2) \in \R^2 : 1-x_1^4-x_2^4 \geq 0\}$ is not a spectrahedron
but it is semidefinite representable:
$$
P = \left\{\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \in \R^2 :
\exists\,
\begin{bmatrix} y_1 \\ y_2 \end{bmatrix} \in \R^2, \,
\begin{bmatrix}
  1+y_1 & y_2 \\
  y_2 & 1-y_1
\end{bmatrix}
\bigoplus
\begin{bmatrix}
  1 & x_1 \\
  x_1 & y_1
\end{bmatrix}
\bigoplus
\begin{bmatrix}
  1 & x_2 \\
  x_2 & y_2
\end{bmatrix}
\succeq 0
\right\}
$$
\end{example}


\section{Polyhedra}

In this section, we define polyhedra over a complete discrete valuation field $K$ with valuation $\val$ and a uniformizer $\pi$, and we discuss the associated linear optimization problem.

\begin{definition}
  \label{def_polyhedra}
  A \emph{polyhedron} is a subset $P \subset K^n$ of the form
  $$
  P = \{x \in K^n : \val(\ell_1 \oplus \cdots \oplus \ell_d) \geq 0 \text{ and }
  \val(m_1 \oplus \cdots \oplus m_e) = +\infty\},
  $$
  for some $\ell_1,\ldots,\ell_d,m_1,\ldots,m_e \in K[x]_1$, where $\val,\geq$ and $=$ are applied entrywise.
  We assume without loss of generality that for every $i=1,\ldots,d$ there exists $x \in P$ such that
  $\val(\ell_i(x))<+\infty$.
\end{definition}

We recall that that the smallest affine space of $K^n$ containing a set $S \subset K^n$ is called its
\emph{affine hull} and denoted $\aff{S}$.
The assumption on forms $\ell_i$ in \Cref{def_polyhedra} implies that the constraint
$\val(m_1 \oplus \cdots \oplus m_e) = +\infty$ defines exactly the affine hull of $P$, in other words
$\aff{P} = \{x \in K^n : m_j(x) = 0,
j=1,\ldots,e\}$ \simone{(il nous faudrait une preuve, du genre: $\val(m(x))=+\infty$ pour tout $x \in P$ si et seulement si $m$ est une combinaison affine de $m_1,\ldots,m_e$.)}
%The \emph{dimension} of $P$ is defined as the dimension of $\aff{P}$ (for $e=0$, $\aff{P}=K^n$ and $P$ has dimension $n$). The \emph{relative interior} of $P$ is defined as $\relint{P} = \{x \in P : \val(\ell_1 \oplus \cdots \oplus \ell_d) < +\infty\}$ (\simone{pas clair si besoin de dimension et relint}).
Remark that \Cref{def_polyhedra} includes the case $d=0$ corresponding to affine spaces, as in the real case.
Moreover by definition the class of polyhedra is closed under intersection.

\begin{example}
  The \emph{closed unit ball} $\OK^n=B_\infty(K^n)$ in $K^n$ for the supremum norm $||\cdot||_{\infty}$ is the
  polyhedron defined as the set of $x=(x_1,\ldots,x_n) \in K^n$ such that $||x||_{\infty} =
  \max_i\{x_i\} \leq 1$, in other words, such that $\val(x_i) \geq 0$, for all $i=1, \ldots, n$.
  In other words, $\OK^n$ is the polyhedron in $K^n$ defined by the affine polynomials
  $\ell_i(x)=x_i$, $i=1,\ldots, n$, and $e=0$ (its affine hull is indeed the whole $K^n$).
\end{example}

A \emph{linear programming problem} (or simply \emph{linear program}) is given by the following
optimization problem:
\begin{equation}
  \tag{LP}\label{LP}
\begin{array}{rcll}
  p^* & := & \inf_{x \in K^n} & \val(\left\langle c, x \right\rangle) \\
  &    & \text{s.t.}         & A x + b \geq 0
\end{array}
\end{equation}
with $c \in K^n$ a fixed vector of size $n$ that represents the cost, $A \in \allmat_{m,n}(K)$, $b \in K^m$,
and $\left\langle c, x \right\rangle := c_1x_1+\cdots +c_nx_n$.
We present an algorithm for solving \eqref{LP} which consists in reducing the matrix $A$ in Smith normal form.
We recall its definition below, in our context.

\begin{definition}[Smith Normal Form]\label{smith_nf} \simone{Je trouve que la SNF devrait être inclue dans les
  préliminaires, car on l'utilise ailleurs, et laisser cette section pour polyèdre+LP}
  Let $M \in \allmat_{m,n}(K)$ be of rank $r$. There exist unique integers $a_1 \leq \cdots \leq a_r$, and
  matrices $P \in \GL_n(\OK)$ and $Q \in \GL_m(\OK)$, such that
  $$
  S := QMP^{-1} = \pi^{a_1} \oplus \pi^{a_2} \oplus \cdots \oplus \pi^{a_r} \oplus {\bf 0}_{\min(m,n)-r}
  $$
  where ${\bf 0}_{\min(m,n)-r}$ is a null square matrix of size $\min(m,n)-r$.
  The matrix $S$ is called the \emph{Smith Normal Form (SNF)} of $M$, and the elements $\pi^{a_i}$ the
  \emph{invariant factors}.
\end{definition}
\begin{remark}
  The valuation of the first invariant factor of the SNF of a matrix
  $M \in \allmat_{n,n}(K)$ is the minimum of the valuations of the entries of
  $M$. In particular, the SNF of $M \in \allmat_n(\OK)$ has entries in $\OK$.
\end{remark}

The most interesting aspect in the SNF regarding the resolution of \ref{LP} is that the transition matrices are invertible in $\OK$. Indeed, if $z \in K^n$ and $M \in \allmat_n(\OK)$ such that $z \geq 0$ then $Mz \geq 0$. The latter property is a direct consequence of $\OK$ being a ring and the converse is true if the matrix $M$ is invertible in $\OK$ \corentin{est-ce qu'il y a besoin de le prouver ?}. Therefore, for all matrix $M \in \allmat_n(K)$ with SNF $S$ and all $z \in K^n$ $Mz \geq 0$ if and only if $Sz \geq 0$. 

That property applied to the matrix $A$ in \ref{LP} allow to reduce the problem to an equivalent simpler iteration of the \ref{LP} problem that will be called \emph{diagonal linear programming problem} \corentin{or maybe reduced linear programming problem?}. This problem is the optimization problem: \simone{il me semble que tout ça n'est pas trop clair, par exemple quelle est la difference entre diagonal LP et associated diagonal LP plus en bas, est-ce qu'il y a vraiment besoin de tout ça, il faut simplifier la presentation}
\begin{equation}
  \tag{dLP}\label{dLP}
\begin{array}{rcll}
  p^* & := & \inf_{y \in K^n} & \val(\left\langle c', y \right\rangle) \\
  &    & \text{s.t.}         & S y + b' \geq 0
\end{array}
\end{equation}
with $c' \in K^n$ a fixed vector of size $n$, $b' \in K^m$ and $S$ a diagonal $m \times n$ matrix of the form $S = s_1 \oplus s_2 \oplus \ldots \oplus s_r \oplus { \bm 0}_{m-r} $ for $r={\rm rank} S$.

The \emph{associated diagonal linear programming problem} of a linear program is the iteration of the \ref{dLP} problem defined by $b' = Qb$, $c' = \left(P^{-1}\right)^T c$ and where $S$ is the Smith normal form of $A$ and $P \in GL_m(\OK)$ and $ Q \in GL_n(\OK)$ are such that $A = Q^{-1} S P$.

A vector $x^* \in K^n$ is \emph{feasible solution} of \ref{LP} if $Ax^* + b \geq 0$. Similarly, a vector $y^* \in K^n$ is a feasible of \ref{dLP} if $Sy^*+b' \geq 0$. We will denote as $Adm$ \corentin{Probablement à changer mais je ne sais pas quel nom lui donner} the set of feasible solution of \ref{dLP}.

\begin{proposition}\label{prop:reduc}
	
	We have then the following results
	\begin{enumerate}
		\item $x^*$ is a feasible solution of \ref{LP} if and only if $y^* = P x^*$ is a feasible solution of the associated \ref{dLP} problem.
		\item $x$ is a solution of \ref{LP} if and only if $y = P x$ is a solution of the associated \ref{dLP} and the the infimum is the same.
		\item \ref{dLP} have feasible solutions if and only if the $m-r$ last coefficients of $b'$ have nonegative valuation, with $r$ the rank of $S$.
		\item If at least one of the $n-r$ last coefficients of $c'$ is non-zero, if \ref{dLP} admits feasible solutions it is unbounded and does not have a solution.
		 
  \end{enumerate}
\end{proposition}
	
\begin{proof}

  First of all, 1. is a consequence of the fact that $Mx^*+b = MP^{-1}y^* +b\geq 0$ if and only if $Q(MP^{-1}y^* + b) = Sy^* + b' \geq 0$ because $Q \in GL_m(\OK)$.

  Then, 2. comes from the fact that for all $c \in K^n$ $\langle c, x\rangle = \langle c, P^{-1}Py \rangle = \langle \left(P^{-1}\right)^T c, y \rangle$.

  A vector $y =  \left[\begin{smallmatrix} y_1 \\ \vdots \\ y_n \end{smallmatrix}\right] \in K^n$ is feasible solution of \ref{dLP} if and only if $\val(s_i y_i + b_i) >=0$ for all $i \in \{1...n\}$ \corentin{préciser les notations}. 
  However, $s_i =0$ for $n-r \leq i\leq n$. Therefore, \ref{dLP} have solution only if the $m-r$ last coefficient of b' are zero.
  
  Conversely, if the $m-r$ last coefficient of $b'$ are zero, the vector $y \in K^n$ such that $y_i = -\frac{-b'_i}{s_i}$ if $1 \leq i \leq r$ and $y_i =0$ otherwise is a feasible solution.

  Finally, let $y^*$ be a feasible solution of \ref{dLP}. Let us suppose there exists $r+1 \leq i \leq m$ such that $c'_i \neq  0$ and fix such $i$. Let us then consider the vector $e^i$ whose only non-zero coefficient is the $i-$th, which is $1$. Then $y^*+\lambda e^i$ is a feasible solution for all $\lambda \in K$ and $\langle c', y^* + \lambda e^i\rangle = \langle c' , y^* \rangle + \lambda c'_i$. In particular, for $\lambda = -\frac{\langle c', y^* \rangle}{c'_i}$ $\val \left( \langle c', y^* + \lambda e ^i \rangle\right) = \val (0) = + \infty$. 

\end{proof}

The two first points of the proposition \ref{prop:reduc} show that we can resolving a linear program is equivalent to resolution the associated \ref{dLP} problem. Furthermore, if one considers only the iteration of \ref{dLP} which have solutions. By point 3. and 4. of proposition \ref{prop:reduc} one can reduce the problem by only taking acount only the $r$ first coefficients of $y, b', c'$ and the submatrix of $S$ made with only $r$ first lines et columns of and which coefficients are exactly the nonzero invariants factors. The set $Adm$ of the feasible solutions can then be written as the set of vectors $y \in \mathbb{Q}_{ p } ^n$ that verifies $\forall 1 \le i\le r \ s_i y_i + b'_i \in \OK$ i.e. that verifies :

\begin{equation}
	\forall 1 \le i\le r  \ y_i \in -\frac{b`_i}{s_i} + \frac{1}{s_i} \OK
\end{equation}


Resolving \ref{dLP} consists in minimizing $\val\left(\left<c',y \right>\right)$ over $Adm$. The image of $Adm$ by $y \mapsto \left<c',y \right>$ is $\sum_{i=1}^r -c'_i.\frac{b'_i}{s_i} + \sum_{i=1}^r\left( \frac{c'_i}{s_{i}} \OK \right)$ which can be rewritten in $\left<c',Adm \right> = \lambda + \pi^{v} \OK$ with $\lambda = \sum_{i=1}^r -c'_i.\frac{b'_i}{s_i}$ and $v = \min\limits_{1\le i\le r} \val \frac{c'_{i}}{s_{i}} $.

Finally, two cases can occur depending on $v$ and the valuation of $\lambda$.
\begin{itemize}
	\item If $\val( \lambda) < v$ the minimum of $y\mapsto \val\left(\left<c',y \right>\right)$ over $Adm$ is reached in any point of $Adm$ and is equal to $\val\left( \lambda\right)$.
	\item If $\val\left( \lambda \right) \ge v$ then $\lambda \in \pi^{v} \OK$ and the minimum is $v $ and is reached in any points $y$ of $Adm$ that verifies 
	\[\val \underset{ \begin{array}{c} 1\le i\le r\\ \val\left(c'_{i}/{s_{i}} \right) = v  \end{array}}{\sum} y_{i} = 0. \]
	
\end{itemize}
\begin{remark}
	To maximize the valuation of a linear map over a convex $p$-adic polyhedron instead of minimizing it (which is equuivalent to minimize the absolute value) the same reasoning can be aplied. The only difference being that if $\val\left( \lambda\right) < v$ the problem is unbounded and as such does not have any solution. 
\end{remark}




\section{Spectrahedra}

\subsection{Definition}
%\newcommand\mat{postive semidefinite matrix } 
\newcommand\Mat{Positive semidefinite matrix }
\newcommand\mats{positive semidefinite matrices }
\newcommand\Mats{positive semidefinite matrices }

\begin{definition}
  We call a matrix $M \in \allmat_{d,d}(K)$ \emph{positive semidefinite} (in symbols $M \succeq 0$)
  if all its eigenvalues have nonnegative valuation in an algebraic closure of $K$.
  We denote by $\allmat_{d,d}^+(K) \subset \allmat_{d,d}(K)$ the set of positive semidefinite matrices.
  The characteristic polynomial of a matrix $M \in \allmat_{d,d}(K)$ is denoted $\chi_M \in K[T]$.
\end{definition}

\begin{theorem}
  \label{caracsdp}
  $M \in \allmat_{d,d}^+(K)$ if and only if $\chi_M \in \OK[T]$.
\end{theorem}
\begin{proof}
  \simone{preuve ?}
\end{proof}

\begin{corollary}\label{cor_caracsdp}
  $\allmat_{d,d}(\OK) \subset \allmat_{d,d}^+(K)$.
\end{corollary}
\begin{proof}
  $\OK$ is a ring therefore if $M \in \allmat_{d,d}(\OK)$, then $\chi_M \in \OK[T]$, thus we conclude
  by \Cref{caracsdp}.
\end{proof}

\begin{example}
  The reverse inclusion of \Cref{cor_caracsdp} is false in general. For instance the characteristic polynomial of
  $M = (\begin{smallmatrix} 5 + {3}/{5} & {4}/{5} \\ {4}/{5} & -{3}/{5} \end{smallmatrix})$ is $\chi_M = T^2-5T-4$. However when seen as a matrix over $K=\mathbb{Q}_5$, then $\chi_M \in \mathbb{Z}_5[T] = \OK[T]$: then $M \in \allmat_{2,2}^+(\mathbb{Q}_5)$, nevertheless $M \not\in \allmat_{2,2}(\mathbb{Z}_5)$, hence $\allmat_{2,2}^+(\mathbb{Q}_5) \not\subset \allmat_{2,2}(\mathbb{Z}_5)$.
\end{example}

\begin{proposition}
  The set $\allmat_{d,d}^+(K)$ is both open and closed.
\end{proposition}
\begin{proof}
Firstly, $\OK[X]$ is closed and open in $\mathbb{Q}_{p}[X]$ (\simone{attention p-adique}) equipped with the infinitiy norm $\|\cdot\|_\infty : P = \sum_{k=1}^{n} a_k X^k \to \sup |a_k|_p$ \simone{attention p-adique}. $\OK$ is indeed the open unit ball for $\|\cdot \|_\infty$ which defines a discrete distance for which open balls are also closed.
Furthermore, $\allmat^+_{d,d}(K) = \chi^{-1}(\OK[X]) $ where $\chi$ is the function that maps its characteristic polynomial to a matrix which is continuous. \simone{mmm je dirais plutôt ``the function that maps a matrix to its characteristic polynomial'', n'est-ce pas ?}
\end{proof}


\simone{que peut-on dire de plus de l'ensemble $\allmat_{d,d}^+(K)$ ? normalement c'est un cône non ? peut être
  à cause de \Cref{caracsdp} c'est un $\OK$-cône mais pas un $K$-cône ? ça serait un peu contre-intuitif, mais
  bon, on est sur un corps abstrait.}

\begin{definition}
  \label{def_spectrahedra}
  Let $\mathcal{L} = A_0+\span{A_1,\ldots,A_n} \subset \allmat_{d,d}(K)$ be an affine space, for some
  $A_0,A_1,\ldots,A_n \in \allmat_{d,d}(K)$.
  The set $\mathcal{L} \cap \allmat_{d,d}^+(K)$ is called a \emph{spectrahedron}. The set 
  $S_A = \{x \in K^n : A_0+x_1A_1+\cdots+x_nA_n \succeq 0\}$, that is the preimage of $\allmat_{d,d}^+(K)$
  under the map $x \mapsto A_0+x_1A_1+\cdots+x_nA_n$, is also called spectrahedron.
\end{definition}

\begin{remark}
  The class of spectrahedra is closed under intersection. Indeed, for affine spaces $\mathcal{L}_1,\mathcal{L}_2$
  one has $(\mathcal{L}_1 \cap \allmat_{d,d}^+(K)) \cap (\mathcal{L}_2 \cap \allmat_{d,d}^+(K)) =
  (\mathcal{L}_1 \cap \mathcal{L}_2) \cap \allmat_{d,d}^+(K)$. Now
  assuming $\mathcal{L}_1 = A_0+\span{A_1,\ldots,A_n}$ and $\mathcal{L}_2 = B_0+\span{B_1,\ldots,B_n}$,
  then $S_A \cap S_B = S_{A \oplus B}$ (indeed both $A \succeq 0$ and $B \succeq 0$ if and only if
  $A \oplus B \succeq 0$).
\end{remark}

%\begin{remark}
%	As in the real case, the spectrahedron associated with the affine plan $\mathcal{L}$ will often be identified with its preimage in $K^s$ (i.e. the set of vectors $x \in K ^s$ so that the linear matrix $A(x) = A_0 + x_1A_1 + \ldots + x_sA_s$ is positive semidefinite with $A_0,A_1,\ldots,A_s$ spanning $\mathcal{L}$). 
%\end{remark}
\begin{proposition}
  A polyhedron is a spectrahedron.
\end{proposition}
\begin{proof}
  Let $\ell_i,m_j \in K[x]_1$, for $i=1,\ldots,d$ and $j=1,\ldots,e$, and let $P = Q \cap L \subset K^n$
  be a polyhedron as in \Cref{def_polyhedra}, for $Q = \{x \in K^n : \val(\ell_i) \geq 0, i=1,\ldots,d\}$
  and $L = \{x \in K^n : \val(m_j) = +\infty, j=1,\ldots,e\}$.
  First, denote by $A(x) = \ell_1 \oplus \cdots \oplus \ell_d \in \allmat_{d,d}(K[x]_1)$,
  so that $A(x) = A_0+x_1A_1+\cdots+x_nA_n$ for some (diagonal) $A_i \in \allmat_{d,d}(K)$.
  We might assume that $A_0,A_1,\ldots,A_n$ are affinely independent, so that the mapping
  $\varphi(x) = A(x)$ is injective. 
  First, remark that $Q=S_A$ and thus $\varphi(Q) = \mathcal{L} \cap \allmat_{d,d}(K)$, with
  $\mathcal{L} = A_0+\span{A_1,\ldots,A_n}$ is a spectrahedron.
  Next, remark that $L \subset K^n$ is the affine space defined by equations $m_1=\ldots=m_e=0$,
  hence $\varphi(L) \subset \allmat_{d,d}(K)$ is an affine space. Since $\varphi$ is injective,
  one has $\varphi(P) = \varphi(Q \cap L) = \varphi(Q) \cap \varphi(L)$ which is the intersection
  of a spectrahedron with an affine space, thus a spectrahedron.
  %Define $B = m_1 \oplus \cdots \oplus m_e \in \allmat_{e,e}(K[x]_1)$
\end{proof}


\subsection{Annuli (couronnes)}
\begin{definition}
	Annulus
	
	We call \emph{annulus} a set $A$ defined as $C = \{x \in K  | a\le \val(x) \le b\} $ for $a < b$ two nonnegative real numbers.
\end{definition}

\begin{theorem}
Annuli are spectrahedral shadows.
\end{theorem} 

\begin{proof}
Let $A$ be the annuli defined by $a<b \in R^*_+$.

We consider for all $x,y \in K $ the matrix  $$M(x,y) :=
\begin{pmatrix} 
	p^ax & 0 & 0 & 0 \\
	0 & p^{-b}y & 0 & 0 \\
	0 & 0 & p^{-1} & p^{-1}x \\
	0 & 0 & p^{-1}y & - p^{-1}  \\
\end{pmatrix} $$ and the associated spectrahedron $\mathcal{S}= \{(x,y) \in K  : M(x,y) \succeq 0\} $

Let us show that $x \in C$ if and only if  $\exists y \in K(x,y) \in \mathcal{S}$.

Let $x,y$ be two $p$-adic numbers.
$M(x,y)$ can be decomposed in three blocks : $p^ax$, $p^{-b}y $ and $M'(x,y) = \begin{pmatrix} p^{-1} & p^{-1}x \\ p^{-1} y & p^{-1}\end{pmatrix} $. Using \ref{caracsdp} we know that $M(x,y)$ is positive semidefinfite if and only if
$
\begin{cases}
  p^ax \ge 0 \\
  p^{-b}y \ge 0\\
  \text{Tr}M'\left( x,y \right) = 0 \ge 0\\
  \text{det} M'(x,y ) = p^{-2}\left( xy-1 \right)  \ge 0 
\end{cases}
$ 
that is if and only if 
\begin{equation}
	\label{eq:caracsdp} 
	\begin{cases} 
		\val\left(x\right)\ge a\\
		\val\left(y\right)\ge -b\\
		p^{-2} \left( xy-1 \right) \ge 0
	\end{cases}
\end{equation}

Therefore $x \in C$ if and only if there exists $y \in K $ so that $(x, y)$ verifies \ref{eq:caracsdp}. Si $x, y$ verifies indeed \ref{caracsdp} then $\val\left(x\right)\ge a$, $\val\left(y\right)\ge -b$ and $p^{-2} \left( xy-1 \right) \ge 0$ implies that $\val\left(x\right)+\val\left(y\right)=\val\left(xy\right) = \val\left(-1\right) =0$ and therefore that $\val\left(x\right)=-\val\left(y\right)\le -(-b)  =b$, so $x \in $. Reciprocally if $x \in C$ then $(x,x^{-1}) $ verifies \ref{eq:caracsdp}  .
\end{proof}

\subsection{Polyhedrality}
Cf. \cite{bhardwaj2015deciding}

\section{Linear matrix inequalities}


\section{Other questions}
\begin{itemize}
\item The projection of a real polyhedron is a real polyhedron (thanks to Fourier-Motzkin elimination procedure). Is it the same for $K$-polyhedra?
\item Annuli are semidefinite representable, we should remark/prove that they are not spectrahedra.
\end{itemize}

\begin{proposition}
Let $\PP \subset K^n$ be a polyhedron and $f: K^n \rightarrow K^m$
be a linear mapping. Then $f(\PP)$ is a polyhedron.
\end{proposition}
\begin{proof}
Let us assume that 
$\PP = \left\lbrace x \in K^n : \val (l_i (x) ) \geq 0, \textrm{ for } i \in I \right\rbrace$ for some
finite set $I \subset \N$ and $l_i \in K[x]_1$, for $i \in I.$ We further assume that $\PP \neq \emptyset$.

Thanks to the Smith Normal Form (see Definition \ref{smith_nf}), $f$
can be written $f=Q^{-1} \Delta P$
with $P \in \GL_n(\OK),$ $Q \in \GL_m(\OK)$
and $\Delta \in \allmat_{n,m}(K)$ of the form $\lambda_1 \oplus \cdots \oplus \lambda_r \oplus {\bf 0}_{\min(m,n)-r}$
  where ${\bf 0}_{\min(m,n)-r}$ is a null square matrix of size $\min(m,n)-r$ for $\lambda_1,\dots,\lambda_r$ non-zero and $r \in \N.$

We first prove the result when $f$ is in $\GL_n(\OK)$.
In that case, $x \in f(P)$ if and only if for all
$i \in I,$
$\val (l_i (f^{-1}(x)) \geq 0$.
The $l_i \circ f^{-1}$ are clearly in $K[x]_1$
and $f(P)$ is a polyhedron.

Similarly, if $f$ is of the form $K^n \rightarrow K^n$,
$(x_1,\dots,x_n) \mapsto (\lambda_1 x_1,\dots,\lambda_n x_n)$
for some $\lambda_i$'s in $K$,
then it is clear that $f(P)$
can be defined by $\val (\widetilde{l_i}(x)) \geq 0$, $i \in I$
with the $\widetilde{l_i}$'s obtained from the $l_i$'s by an
obvious change of variables.

Now, we turn our attention to the $\Delta$ part of $f.$
We first assume that $f$ is a projection 
of the form $K^n \rightarrow K^{n+1},$
$(x_1,\dots,x_{n-1},x_n)\mapsto (x_1,\dots,x_{n-1}).$

Let us write the conditions defining $\PP$
in matrix form:
$\val(A X+B) \geq 0$
with $A \in M_{q,n}(K)$, $B \in K^q$
and $X=(x_1,\dots,x_n)^\intercal.$

We can compute a Smith Normal Form
of the $q \times (n-1)$ matrix defined by the 
$n-1$ first columns of $A$
to obtain a decomposition of the form:
\[ Q_A A P_A^{-1} = \begin{bmatrix}
\delta_1	& 		& 			&   &		 &  &a_1	\\
			& \ddots& 			& 0	&		 &	&		\\
			&		& \delta_l  &   & 		 &	&		\\
			&		&			&0  & 		 &	& 		\\
			&		&			&   & \ddots &	&		\\
			&		&			&	&		 & 0&a_{n-1} \\
			&		&			&	&		 &	&a_n 	\\
			&		&			&	&		 &	&    	\\
			&		&			&	&		 &	&a_q 	\\			
\end{bmatrix},\]
with $Q_A \in \GL_q(\OK)$ and $P_A \in \GL_n(\OK)$ such that $P_A(e_n)=e_n.$

Multiplying on the left by $Q_A^{\pm 1}$ does not
modify whether the valuation inequalities are satisfied.
Moreover, thanks to our previous on the case when $f$ is an automorphism,
$\PP$ can be written
$\PP=P_A^{-1}(\PP_2)$ for some polyhedron $\PP_2 \in K^n$
and we are reduced to proving that
$f(\PP_2)$ is polyhedron for $f$ still the canonical projection
$K^n \rightarrow K^{n-1}$ and $\PP_2$
defined by the linear matrix inequality (for some $B_2 \in K^q$):
\[  \begin{bmatrix}
\delta_1	& 		& 			&   &		 &  &a_1	\\
			& \ddots& 			& 0	&		 &	&		\\
			&		& \delta_l  &   & 		 &	& \vdots\\
			&		&			&0  & 		 &	& 		\\
			&		&			&   & \ddots &	&		\\
			&		&			&	&		 & 0&a_{n-1} \\
			&		&			&	&		 &	&a_n 	\\
			&		&			&	&		 &	& \vdots   	\\
			&		&			&	&		 &	&a_q 	\\			
\end{bmatrix} \begin{bmatrix} x_1 \\ \\ \\ \\ \\ \vdots \\ \\ \\ \\ x_n \\ \end{bmatrix} + B_2 \geq 0.\]



We remark that 
$a_s x_n + b_s \geq 0$
if and only if $x_n = -a_s^{-1} b_s + O(\pi^{- \val(a_s)}).$
This exactly corresponds to $x_n \in B(-a_s^{-1} b_s, 2^{\val(a_s)}).$
Since the conditions have to be compatible (we have assumed
$\PP$ not empty), and thanks to ultrametricity,  
the intersection of these conditions for 
$s \in \llbracket l+1,q \rrbracket$
is then given by the smallest of these balls.
Let us assume it is the one defined for $l=n.$
The only condition on $x_n$
is then $\val(a_nx_n +b_n) \geq 0.$

Thanks to the above discussion on diagonal mapping,
we can further assume that the $\delta_i$'s and $a_n$ are all $1$'s
and are reduce to $\PP_2$ defined by the linear matrix inequality :
\[  \begin{bmatrix}
1	& 		& 			&   &		 &  &a_1	\\
			& \ddots& 			& 0	&		 &	&		\\
			&		& 1  &   & 		 &	& \\
			&		&			&0  & 		 &	& 	\vdots	\\
			&		&			&   & \ddots &	&		\\
			&		&			&	&		 & 0&a_{n-1} \\
			&		&			&	&		 &	&1 	\\
		
\end{bmatrix} \begin{bmatrix} x_1 \\ \\  \\ \\ \vdots \\  \\ \\ x_n \\ \end{bmatrix} + \begin{bmatrix} b_1 \\ \\ \\  \\ \vdots  \\ \\ \\ b_n \\ \end{bmatrix}  \geq 0.\]
Finally, we can also assume that, up to a permutation of the variables, $\val(a_1)= \min_{i=1}^{n-1} \val(a_i).$
We distinguish two cases: $\val(a_1) \geq 0$ and $\val(a_1)<0.$

Let us first assume that $\val(a_1) \geq 0$

Let $x \in \PP_2$.
Then $x_n=-b_n+O(1)$
and $x_1+a_1 x_n+b_1=O(1).$
Consequently, $x_1-a_1 b_n +b_1=O(1)+O(\pi^{\val(a_1)})=O(1).$
Similarly, for all $i \in \llbracket 2,n-1 \rrbracket,$
$x_i-a_ib_n+b_i=O(1)+O(\pi^{\val(a_i)})=O(1).$

We define the polyhedron $\Qc \subset K^{n-1}$ by the following inequalities:
 for all $i \in \llbracket 1,n-1 \rrbracket,$
$\val(x_i-a_ib_n+b_i) \geq 0.$

Then the previous computations prove that $f(\PP_2)\subset \Qc.$
Conversely, let $(x_1,\dots,x_{n-1}) \in \Qc.$
Then let $x_n := -b_n.$

We check that for $i \in \llbracket 1,n-1 \rrbracket,$
$x_i+a_ix_n+b_i=x_i-a_ib_n+b_i=O(1),$
and $x_n+b_n=O(1)$. Hence $(x_1,\dots,x_n) \in \PP_2$
which means that $(x_1,\dots,x_{n-1}) \in f(\PP_2).$
Thus $f(\PP_2)= \Qc$ and $f(\PP_2)$ is a polyhedron.

We now deal with the second case, with $\val(a_1)<0.$
Let $x \in \PP_2$.
Then $x_n=-b_n+O(1)$
and $x_1+a_1 x_n+b_1=O(1).$
Consequently, $x_1-a_1 b_n +b_1=O(1)+O(\pi^{\val(a_1)})=O(\pi^{\val(a_1)})).$
Thus $a_1^{-1}x_1- b_n +a_1^{-1}b_1=O(1)$.
%and $x_n=-a_1^{-1}(x_1+b_1)+O(1).$
In addition, $x_n=-a_1^{-1}(x_1+b_1)+O(\pi^{-\val(a_1)}).$
We plug this equality in 
$x_i+a_i x_n+b_i=O(1)$ to get
$x_i-a_1^{-1}a_i(x_1+b_1)+b_i=O(1)+O(\pi^{\val(a_i)-\val(a_1)})=O(1)$
using that $\val(a_i) \geq \val (a_1).$

We define the polyhedron $\Qc \subset K^{n-1}$ by the following inequalities:
$\val(a_1^{-1}x_1- b_n +a_1^{-1}b_1) \geq 0$ and for all $i \in \llbracket 2,n-1 \rrbracket,$
$\val(x_i-a_1^{-1}a_i(x_1+b_1)+b_i) \geq 0.$

Then the previous computations prove that $f(\PP_2)\subset \Qc.$
Conversely, let $(x_1,\dots,x_{n-1}) \in \Qc.$
Let $x_n := -a_1^{-1}(x_1+b_1).$
Then
$x_1+a_1 x_n+b_1=0=O(1).$
Let $i \in \llbracket 2,n-1 \rrbracket,$
then $x_i+a_i x_n+b_i=x_i-a_1^{-1}a_i(x_1+b_1)+b_i=O(1)$
since $(x_1,\dots,x_{n-1}) \in \Qc.$
Finally, 
$x_n+b_n=-a_1^{-1}(x_1+b_1)+b_n=O(1)$ thanks to the inequality satisfied by $x_1.$
Hence $(x_1,\dots,x_n) \in \PP_2$
which means that $(x_1,\dots,x_{n-1}) \in f(\PP_2).$
Thus $f(\PP_2)= \Qc$ and $f(\PP_2)$ is a polyhedron,
and it has been proved in both cases.

Therefore, if $f$ is the projection 
$(x_1,\dots,x_{n-1},x_n)\mapsto (x_1,\dots,x_{n-1})$ 
and $\PP$ is a polyhedron in $K^n$,
then $f(\PP)$ is a polyhedron.

\tristan{Attention, à partir de maintenant,
il faut ajouter à la définition qu'on peut
fixer des points!
Cela revient à ajouter des conditions
$\val = + \infty.$}

It is also clear that
if $f$ is the immersion 
$K^l \rightarrow K^n$
$(x_1,\dots,x_l)\mapsto (x_1,\dots,x_l,0,\dots,0)$ 
and $\PP$ is a polyhedron in $K^n$,
then $f(\PP)$ is a polyhedron.


We now prove that for
$\Delta$ a Smith Normal Form
and $\PP$ a polyhedron,
$\Delta(\PP)$ is a polyhedron.
Then $\Delta$ is the composition
of the immersion 
$K^l \rightarrow K^n$
$(x_1,\dots,x_l)\mapsto (x_1,\dots,x_l,0,\dots,0),$ 
 the diagonal invertible mapping
$K^l \rightarrow K^l$,
$(x_1,\dots,x_l)\mapsto (\delta_1,\dots,\delta_l x_l)$,
and the projections
$(x_1,\dots,x_{l+1})\mapsto (x_1,\dots,x_{l}),$
 $(x_1,\dots,x_{l+2})\mapsto (x_1,\dots,x_{l+1}),$
 $\dots,$
 $(x_1,\dots,x_{n})\mapsto (x_1,\dots,x_{n-1}).$
 Thus $\Delta(\PP)$ is a polyhedron thanks to the previous 
 results on image of polyhedron.

Finally, if $f: K^n \rightarrow K^m$
is a linear mapping and
$f=Q^{-1} \Delta P$ is its Smith Normal Form
with $P \in \GL_n(\OK),$ $Q \in \GL_m(\OK)$
and $\Delta \in \allmat_{n,m}(K)$,
then
$P(\PP)$ is a polyhedron,
$\Delta (P(\PP))$ also,
and finally $f(\PP)=Q^{-1} (\Delta (P(\PP)))$
is a polyhedron.
This concludes the proof.
\end{proof}


\printbibliography

\end{document}
